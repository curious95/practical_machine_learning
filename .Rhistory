setwd("~/DevX/rdev/pml peer graded assingment")
setwd("~/DevX/rdev/pml peer graded assingment")
setwd("~/DevX/rdev/pml peer graded assingment")
setwd("~/DevX/rdev/pml peer graded assingment")
setwd("~/DevX/rdev/pml peer graded assingment")
library(dplyr)
install.packages("caret")
install.packages("caret")
install.packages("minga")
install.packages(c("openssl", "proto"))
install.packages("caret")
install.packages("caret")
library(caret)
clear
install.packages("gbm")
library(dplyr)
library(caret)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
library(dplyr)
library(caret)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE)
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE)
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE)
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE)
}
library(dplyr)
library(caret)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE)
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE)
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE)
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE)
}
View(train_data)
summarise(train_data)
?dplyr
?`dplyr-package`
browseVignettes(package = "dplyr")
head(train_data)
summarise(train_data)
summarise(as.data.frame(train_data))
summarise(as.data.frame(test_data))
summarize(tbl_df(train_data))
train_tbl<-tbl_df(train_data)
summarize(train_tbl)
View(train_tbl)
train_data<-train_data[, colSums(is.na(train_data)) != nrow(train_data)]
View(train_data)
colSums(is.na(train_data))
train_data<-train_data[, colSums(is.na(train_data)) > 19000]
train_data<-train_data[, colSums(is.na(train_data)) > 19000]
train_data<-train_data[, colSums(is.na(train_data)) > nrow(train_data)*0.90]
library(dplyr)
library(caret)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE)
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE)
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE)
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE)
}
train_data<-train_data[, colSums(is.na(train_data)) > nrow(train_data)*0.90]
test_data<-train_data[, colSums(is.na(test_data)) > nrow(test_data)*0.90]
View(test_data)
train_data<-train_data[, colSums(is.na(train_data)) > nrow(train_data)*0.90]
train_data<-train_data[, colSums(is.na(train_data)) > nrow(train_data)*0.90]
test_data<-test_data[, colSums(is.na(test_data)) > nrow(test_data)*0.90]
train_data<-train_data[, colSums(is.na(train_data)) > nrow(train_data)*0.90]
test_data<-test_data[, colSums(is.na(test_data)) > nrow(test_data)*0.90]
View(train_data)
train_data<-train_data[, colSums(is.na(train_data)) < nrow(train_data)*0.90]
test_data<-test_data[, colSums(is.na(test_data)) < nrow(test_data)*0.90]
nrow(train_data)*0.90
library(dplyr)
library(caret)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE)
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE)
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE)
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE)
}
train_data<-train_data[, colSums(is.na(train_data)) > nrow(train_data)*0.90]
test_data<-test_data[, colSums(is.na(test_data)) > nrow(test_data)*0.90]
View(train_data)
View(test_data)
library(dplyr)
library(caret)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE)
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE)
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE)
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE)
}
train_data<-train_data[, !colSums(is.na(train_data)) > nrow(train_data)*0.90]
test_data<-test_data[, !colSums(is.na(test_data)) > nrow(test_data)*0.90]
View(train_data)
library(dplyr)
library(caret)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = NA)
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = NA)
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = NA)
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = NA)
}
train_data<-train_data[, !colSums(is.na(train_data)) > nrow(train_data)*0.90]
test_data<-test_data[, !colSums(is.na(test_data)) > nrow(test_data)*0.90]
View(test_data)
View(train_data)
library(dplyr)
library(caret)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}
train_data<-train_data[, !colSums(is.na(train_data)) > nrow(train_data)*0.90]
test_data<-test_data[, !colSums(is.na(test_data)) > nrow(test_data)*0.90]
library(dplyr)
library(caret)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}
#removing the columns from both test and training data set where 50% of
train_data<-train_data[, !colSums(is.na(train_data)) > nrow(train_data)*0.50]
test_data<-test_data[, !colSums(is.na(test_data)) > nrow(test_data)*0.50]
train_data<-train_data[, !colSums(is.na(train_data)) > nrow(train_data)*0.50]
training_cols<-colnames(train_data)
test_data<-test_data[, training_cols]
removed_cols<-colSums(is.na(train_data)) > nrow(train_data)*0.50
removed_cols<-!colSums(is.na(train_data)) > nrow(train_data)*0.50
removed_cols<-colnames(train_data[,colSums(is.na(train_data)) > nrow(train_data)*0.50])
removed_cols<-colnames(train_data[,colSums(is.na(train_data)) > nrow(train_data)*0.50])
library(dplyr)
library(caret)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}
#removing the columns from both test and training data set where 50% of values in columns are empty
removed_cols<-colnames(train_data[,colSums(is.na(train_data)) > nrow(train_data)*0.50])
train_data<-train_data[, !colSums(is.na(train_data)) > nrow(train_data)*0.50]
test_data<- test_data[,!removed_cols]
test_data<- test_data[,!names(test_data) in removed_cols]
test_data<- test_data[,!names(test_data) %in% removed_cols]
View(test_data)
library(dplyr)
library(caret)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}
#removing the columns from both test and training data set where 50% of values in columns are empty
#Marking columns for removal
removed_cols<-colnames(train_data[,colSums(is.na(train_data)) > nrow(train_data)*0.50])
#Removing from training set
train_data<-train_data[,!names(train_data) %in% removed_cols]
#Removing from test set
test_data<- test_data[,!names(test_data) %in% removed_cols]
#Marking Unnecessary columns
un_cols<- c("V1", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2","cvtd_timestamp", "new_window", "num_window")
#Removing Unnecessary columns from training set
train_data<-train_data[,!names(train_data) %in% un_cols]
#Removing Unnecessary columns from test set
test_data<- test_data[,!names(test_data) %in% un_cols]
View(train_data)
View(test_data)
View(test_data)
View(train_data)
library(dplyr)
library(caret)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}
#removing the columns from both test and training data set where 50% of values in columns are empty
#Marking columns for removal
removed_cols<-colnames(train_data[,colSums(is.na(train_data)) > nrow(train_data)*0.50])
#Removing from training set
train_data<-train_data[,!names(train_data) %in% removed_cols]
#Removing from test set
test_data<- test_data[,!names(test_data) %in% removed_cols]
#Marking Unnecessary columns
un_cols<- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2","cvtd_timestamp", "new_window", "num_window")
#Removing Unnecessary columns from training set
train_data<-train_data[,!names(train_data) %in% un_cols]
#Removing Unnecessary columns from test set
test_data<- test_data[,!names(test_data) %in% un_cols]
View(test_data)
View(train_data)
library(dplyr)
library(caret)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}
#removing the columns from both test and training data set where 50% of values in columns are empty
#Marking columns for removal
removed_cols<-colnames(train_data[,colSums(is.na(train_data)) > nrow(train_data)*0.50])
#Removing from training set
train_data<-train_data[,!names(train_data) %in% removed_cols]
#Removing from test set
test_data<- test_data[,!names(test_data) %in% removed_cols]
#Marking Unnecessary columns
un_cols<- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2","cvtd_timestamp", "new_window", "num_window")
#Removing Unnecessary columns from training set
train_data<-train_data[,!names(train_data) %in% un_cols]
#Removing Unnecessary columns from test set
test_data<- test_data[,!names(test_data) %in% un_cols]
dim(train_data)
dim(test_data)
tbl_df(train_data)
summarise(tbl_df(train_data))
summarise(tbl_df(as.data.frame(train_data)))
library(dplyr)
install.packages("corrplot")
library(corrplot)
M<-cor(train_data)
View(train_data)
M<-cor(train_data[,-53])
corrplot(M, method = "circle")
View(M)
m<-[abs(m)<0.5]<-NA
m[abs(m)<0.5]<-NA
M[abs(M)<0.5]<-NA
M<-na.omit(M)
library(dplyr)
library(caret)
library(corrplot)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}
#removing the columns from both test and training data set where 50% of values in columns are empty
#Marking columns for removal
removed_cols<-colnames(train_data[,colSums(is.na(train_data)) > nrow(train_data)*0.50])
#Removing from training set
train_data<-train_data[,!names(train_data) %in% removed_cols]
#Removing from test set
test_data<- test_data[,!names(test_data) %in% removed_cols]
#Marking Unnecessary columns
un_cols<- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2","cvtd_timestamp", "new_window", "num_window")
#Removing Unnecessary columns from training set
train_data<-train_data[,!names(train_data) %in% un_cols]
#Removing Unnecessary columns from test set
test_data<- test_data[,!names(test_data) %in% un_cols]
dim(train_data)
dim(test_data)
train_data$
M<-cor(train_data)
M<-cor(train_data)
M<-cor(train_data[,-53])
M[abs(M)<0.5]<-NA
library(reshape2)
z<-na.omit(melt(M))
View(z)
z<-melt(z)
z<-na.omit(melt(M))
plot(z$value,x = z$Var1,y = z$Var2)
ggplot(data = m)
ggplot(data = z)
library(scatterplot3d)
install.packages("scatterplot3d")
library(scatterplot3d)
scatterplot3d(x = z$Var1,y=z$Var2,z=z$value)
head(m)
head(z)
z[order(-abs(z$value)),]
corrs<-cor(train_data[,-53])
library(dplyr)
library(caret)
library(corrplot)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}
#removing the columns from both test and training data set where 50% of values in columns are empty
#Marking columns for removal
removed_cols<-colnames(train_data[,colSums(is.na(train_data)) > nrow(train_data)*0.50])
#Removing from training set
train_data<-train_data[,!names(train_data) %in% removed_cols]
#Removing from test set
test_data<- test_data[,!names(test_data) %in% removed_cols]
#Marking Unnecessary columns
un_cols<- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2","cvtd_timestamp", "new_window", "num_window")
#Removing Unnecessary columns from training set
train_data<-train_data[,!names(train_data) %in% un_cols]
#Removing Unnecessary columns from test set
test_data<- test_data[,!names(test_data) %in% un_cols]
dim(train_data)
dim(test_data)
train_data$
corrs<-cor(train_data[,-53])
corrs[corrs==1]<-NA
corrs[abs(corrs)<0.5]<-NA
corrs<-na.omit(melt(corrs))
corrs[order(-abs(z$value)),]
library(dplyr)
library(caret)
library(corrplot)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}
#removing the columns from both test and training data set where 50% of values in columns are empty
#Marking columns for removal
removed_cols<-colnames(train_data[,colSums(is.na(train_data)) > nrow(train_data)*0.50])
#Removing from training set
train_data<-train_data[,!names(train_data) %in% removed_cols]
#Removing from test set
test_data<- test_data[,!names(test_data) %in% removed_cols]
#Marking Unnecessary columns
un_cols<- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2","cvtd_timestamp", "new_window", "num_window")
#Removing Unnecessary columns from training set
train_data<-train_data[,!names(train_data) %in% un_cols]
#Removing Unnecessary columns from test set
test_data<- test_data[,!names(test_data) %in% un_cols]
dim(train_data)
dim(test_data)
corrs<-cor(train_data[,-53])
corrs[corrs==1]<-NA
corrs[abs(corrs)<0.5]<-NA
corrs<-na.omit(melt(corrs))
corrs[order(-abs(z$value)),]
library(dplyr)
library(caret)
library(corrplot)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-training.csv") || !file.exists("pml-testing.csv")){
#download.file(train_url,method = "curl",destfile = "pml-training.csv")
download.file(test_url,method = "curl",destfile = "pml-testing.csv")
downloadDate<- date()
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}else{
train_data<-read.csv("pml-training.csv",sep = ",",header = TRUE,na.strings = c("",NA))
test_data<-read.csv("pml-testing.csv",sep = ",",header = TRUE,na.strings = c("",NA))
}
#removing the columns from both test and training data set where 50% of values in columns are empty
#Marking columns for removal
removed_cols<-colnames(train_data[,colSums(is.na(train_data)) > nrow(train_data)*0.50])
#Removing from training set
train_data<-train_data[,!names(train_data) %in% removed_cols]
#Removing from test set
test_data<- test_data[,!names(test_data) %in% removed_cols]
#Marking Unnecessary columns
un_cols<- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2","cvtd_timestamp", "new_window", "num_window")
#Removing Unnecessary columns from training set
train_data<-train_data[,!names(train_data) %in% un_cols]
#Removing Unnecessary columns from test set
test_data<- test_data[,!names(test_data) %in% un_cols]
dim(train_data)
dim(test_data)
corrs<-cor(train_data[,-53])
corrs[corrs==1]<-NA
corrs[abs(corrs)<0.5]<-NA
corrs<-na.omit(melt(corrs))
corrs[order(-abs(corrs$value)),]
corrs[order(-abs(corrs$value)),20]
corrs[order(-abs(corrs$value)),][1:20]
corrs[order(-abs(corrs$value)),][20,]
corrs[order(-abs(corrs$value)),][1:20,]
install.packages("e1071")
install.packages("randomForest")
library(randomForest)
